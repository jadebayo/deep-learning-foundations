{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 50:\n",
      "Image - Min Value: 8 Max Value: 243\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff06804ff28>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 50\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = np.array(x,dtype=np.float32)\n",
    "    xmin = np.min(x)\n",
    "    xmax = np.max(x)\n",
    "    x_norm = np.apply_along_axis(lambda m: (m-xmin)/(xmax-xmin), 1, x)\n",
    "    return x_norm\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    one_hot = np.zeros((len(x), 10), dtype=np.int)\n",
    "    for i in range(len(x)):\n",
    "            one_hot[i][x[i]] =  1   \n",
    "    return one_hot\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input = tf.placeholder(tf.float32, name='x', shape=[None,image_shape[0], image_shape[1], image_shape[2]])\n",
    "    return input\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    input = tf.placeholder(tf.int32, name='y', shape=[None, n_classes])\n",
    "    return input\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    input = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    return input\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_tensor.get_shape()[3].value, conv_num_outputs], stddev=0.1))\n",
    "    biases = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor,weights,strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, biases)\n",
    "    x_tensor =tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(x_tensor, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = x_tensor.get_shape().as_list()       \n",
    "    dim = np.prod(shape[1:])  \n",
    "    return tf.reshape(x_tensor, [-1, dim])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    features = x_tensor.get_shape()[1].value\n",
    "    weight = tf.Variable(tf.truncated_normal([features, num_outputs], stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    \n",
    "    return tf.nn.relu(tf.add(tf.matmul(x_tensor, weight),bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Functionl\n",
    "    return fully_conn(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, 16, (3,3),(1,1), (2,2), (1,1))\n",
    "    conv = conv2d_maxpool(conv, 16,(3,3),(1,1), (2,2), (1,1))\n",
    "    conv = conv2d_maxpool(conv, 32,(3,3),(1,1), (2,2), (1,1))\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    fc = flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    \n",
    "    fc = fully_conn(fc, 512)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "    fc = fully_conn(fc, 64)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fc, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x:valid_features, y:valid_labels, keep_prob:1.0})\n",
    "\n",
    "    print('Loss: {:>10.5f} Validation Accuracy: {:.2f}%'.format(loss,valid_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.19803 Validation Accuracy: 24.22%\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    2.07079 Validation Accuracy: 29.86%\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.73336 Validation Accuracy: 39.28%\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    1.46357 Validation Accuracy: 44.52%\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    1.12428 Validation Accuracy: 51.78%\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    0.81695 Validation Accuracy: 53.06%\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    0.69517 Validation Accuracy: 55.58%\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.55759 Validation Accuracy: 55.26%\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.44544 Validation Accuracy: 56.22%\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.30110 Validation Accuracy: 57.10%\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.19574 Validation Accuracy: 57.82%\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.17530 Validation Accuracy: 56.14%\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.15633 Validation Accuracy: 54.24%\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.14303 Validation Accuracy: 55.26%\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.05879 Validation Accuracy: 55.96%\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.02835 Validation Accuracy: 56.18%\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.02628 Validation Accuracy: 57.06%\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.01513 Validation Accuracy: 57.64%\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.01793 Validation Accuracy: 57.04%\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.01909 Validation Accuracy: 56.36%\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.01919 Validation Accuracy: 56.70%\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.01195 Validation Accuracy: 54.60%\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.00520 Validation Accuracy: 55.22%\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.00233 Validation Accuracy: 57.38%\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.00364 Validation Accuracy: 55.42%\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.00083 Validation Accuracy: 58.02%\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.00283 Validation Accuracy: 57.24%\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.00206 Validation Accuracy: 57.34%\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.00136 Validation Accuracy: 57.90%\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.00063 Validation Accuracy: 56.72%\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.00038 Validation Accuracy: 58.20%\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.00058 Validation Accuracy: 57.16%\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.00052 Validation Accuracy: 57.30%\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.00072 Validation Accuracy: 57.70%\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.00042 Validation Accuracy: 57.24%\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.00135 Validation Accuracy: 57.60%\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.00038 Validation Accuracy: 57.02%\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.00034 Validation Accuracy: 57.26%\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.00015 Validation Accuracy: 58.34%\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.00044 Validation Accuracy: 56.84%\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.00024 Validation Accuracy: 57.10%\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.00057 Validation Accuracy: 56.46%\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.00024 Validation Accuracy: 56.92%\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.00034 Validation Accuracy: 56.36%\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.00019 Validation Accuracy: 56.86%\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.00031 Validation Accuracy: 55.64%\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 56.14%\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 56.84%\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.00004 Validation Accuracy: 56.62%\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.00049 Validation Accuracy: 57.08%\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.00018 Validation Accuracy: 57.46%\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.00037 Validation Accuracy: 56.72%\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.00007 Validation Accuracy: 57.68%\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.00056 Validation Accuracy: 55.56%\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.00579 Validation Accuracy: 56.20%\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.00050 Validation Accuracy: 56.86%\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.00007 Validation Accuracy: 57.02%\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.00005 Validation Accuracy: 57.10%\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 56.94%\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 56.50%\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 56.90%\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 58.04%\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 57.92%\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 58.28%\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 57.04%\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.00023 Validation Accuracy: 57.58%\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.00089 Validation Accuracy: 56.38%\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.00039 Validation Accuracy: 56.84%\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.00011 Validation Accuracy: 56.14%\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 58.12%\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.00005 Validation Accuracy: 56.34%\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 56.48%\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 58.32%\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 56.66%\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.00144 Validation Accuracy: 54.12%\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 57.38%\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 57.36%\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.00005 Validation Accuracy: 55.84%\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.00048 Validation Accuracy: 54.62%\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.00020 Validation Accuracy: 57.96%\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 56.76%\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.00004 Validation Accuracy: 57.98%\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 56.64%\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 57.46%\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 56.70%\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 57.44%\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.00037 Validation Accuracy: 55.72%\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.00005 Validation Accuracy: 56.32%\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 57.14%\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 57.16%\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 57.20%\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.00005 Validation Accuracy: 55.38%\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.00004 Validation Accuracy: 56.36%\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 57.76%\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.00032 Validation Accuracy: 55.44%\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 56.94%\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 56.02%\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 56.40%\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 56.68%\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 56.96%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.19453 Validation Accuracy: 27.26%\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:    1.58693 Validation Accuracy: 39.28%\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:    1.22382 Validation Accuracy: 45.98%\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:    1.40704 Validation Accuracy: 49.64%\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:    1.44300 Validation Accuracy: 53.06%\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.35046 Validation Accuracy: 55.60%\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:    1.04445 Validation Accuracy: 55.66%\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:    0.94316 Validation Accuracy: 55.12%\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:    1.02911 Validation Accuracy: 58.40%\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:    0.89913 Validation Accuracy: 59.08%\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    0.97917 Validation Accuracy: 59.94%\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:    0.78115 Validation Accuracy: 60.46%\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:    0.66313 Validation Accuracy: 60.44%\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:    0.69383 Validation Accuracy: 62.46%\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:    0.60006 Validation Accuracy: 61.38%\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    0.68560 Validation Accuracy: 63.66%\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:    0.54862 Validation Accuracy: 63.20%\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:    0.43331 Validation Accuracy: 64.04%\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:    0.53728 Validation Accuracy: 64.30%\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:    0.32353 Validation Accuracy: 63.32%\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    0.44651 Validation Accuracy: 64.78%\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:    0.41098 Validation Accuracy: 64.08%\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:    0.26042 Validation Accuracy: 65.20%\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:    0.37180 Validation Accuracy: 64.94%\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:    0.23057 Validation Accuracy: 64.30%\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    0.34451 Validation Accuracy: 64.40%\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:    0.25081 Validation Accuracy: 65.48%\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:    0.21905 Validation Accuracy: 63.02%\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:    0.23693 Validation Accuracy: 65.52%\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:    0.26401 Validation Accuracy: 62.72%\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    0.19088 Validation Accuracy: 65.84%\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:    0.19041 Validation Accuracy: 65.04%\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:    0.11729 Validation Accuracy: 62.32%\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:    0.12563 Validation Accuracy: 65.78%\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:    0.14726 Validation Accuracy: 64.12%\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.16947 Validation Accuracy: 65.24%\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:    0.10262 Validation Accuracy: 65.82%\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:    0.08582 Validation Accuracy: 65.36%\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:    0.09364 Validation Accuracy: 65.38%\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:    0.09071 Validation Accuracy: 65.22%\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.09236 Validation Accuracy: 65.70%\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:    0.06945 Validation Accuracy: 66.98%\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:    0.10219 Validation Accuracy: 64.62%\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:    0.04985 Validation Accuracy: 66.08%\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:    0.03575 Validation Accuracy: 67.54%\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.04498 Validation Accuracy: 67.04%\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:    0.03626 Validation Accuracy: 66.18%\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:    0.04488 Validation Accuracy: 65.52%\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:    0.05596 Validation Accuracy: 66.52%\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:    0.04573 Validation Accuracy: 66.06%\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.03844 Validation Accuracy: 64.86%\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:    0.02441 Validation Accuracy: 65.22%\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:    0.01393 Validation Accuracy: 64.72%\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:    0.01723 Validation Accuracy: 64.50%\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:    0.01554 Validation Accuracy: 65.66%\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.03472 Validation Accuracy: 66.08%\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:    0.01510 Validation Accuracy: 64.56%\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:    0.02045 Validation Accuracy: 64.38%\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:    0.01136 Validation Accuracy: 64.88%\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:    0.00818 Validation Accuracy: 64.78%\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.01989 Validation Accuracy: 65.86%\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:    0.00789 Validation Accuracy: 66.10%\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:    0.00483 Validation Accuracy: 66.46%\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:    0.02141 Validation Accuracy: 65.02%\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:    0.00399 Validation Accuracy: 65.96%\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.00675 Validation Accuracy: 65.60%\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:    0.00301 Validation Accuracy: 66.90%\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:    0.00670 Validation Accuracy: 66.10%\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:    0.00878 Validation Accuracy: 65.54%\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:    0.00170 Validation Accuracy: 66.06%\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.00792 Validation Accuracy: 66.44%\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:    0.00557 Validation Accuracy: 67.06%\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:    0.01022 Validation Accuracy: 65.28%\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:    0.01225 Validation Accuracy: 65.26%\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:    0.00223 Validation Accuracy: 66.04%\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.00764 Validation Accuracy: 65.20%\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:    0.00361 Validation Accuracy: 66.70%\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:    0.00552 Validation Accuracy: 66.04%\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:    0.00834 Validation Accuracy: 65.62%\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:    0.00062 Validation Accuracy: 67.12%\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.00281 Validation Accuracy: 66.20%\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:    0.00268 Validation Accuracy: 66.26%\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:    0.00311 Validation Accuracy: 66.84%\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:    0.00426 Validation Accuracy: 64.34%\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:    0.00105 Validation Accuracy: 66.62%\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.00138 Validation Accuracy: 66.32%\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:    0.00103 Validation Accuracy: 65.60%\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:    0.00140 Validation Accuracy: 65.68%\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:    0.00688 Validation Accuracy: 66.04%\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:    0.00086 Validation Accuracy: 66.08%\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.00742 Validation Accuracy: 65.80%\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:    0.00086 Validation Accuracy: 66.42%\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:    0.00118 Validation Accuracy: 66.50%\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:    0.00385 Validation Accuracy: 64.94%\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:    0.00231 Validation Accuracy: 65.98%\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.00090 Validation Accuracy: 66.02%\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:    0.00069 Validation Accuracy: 67.36%\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:    0.00059 Validation Accuracy: 65.82%\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:    0.00148 Validation Accuracy: 65.12%\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:    0.00024 Validation Accuracy: 67.06%\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.00119 Validation Accuracy: 66.28%\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:    0.00199 Validation Accuracy: 65.80%\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:    0.00101 Validation Accuracy: 66.56%\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:    0.00084 Validation Accuracy: 65.94%\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:    0.00079 Validation Accuracy: 66.74%\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.00103 Validation Accuracy: 66.20%\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:    0.00343 Validation Accuracy: 65.90%\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:    0.00098 Validation Accuracy: 65.32%\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:    0.00029 Validation Accuracy: 66.54%\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:    0.00085 Validation Accuracy: 65.78%\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.00173 Validation Accuracy: 66.40%\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:    0.00026 Validation Accuracy: 66.56%\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:    0.00061 Validation Accuracy: 65.82%\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:    0.00064 Validation Accuracy: 65.82%\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:    0.00097 Validation Accuracy: 65.38%\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.00033 Validation Accuracy: 65.68%\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:    0.00014 Validation Accuracy: 66.16%\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:    0.00025 Validation Accuracy: 66.52%\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:    0.00015 Validation Accuracy: 64.90%\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:    0.00030 Validation Accuracy: 66.94%\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.00526 Validation Accuracy: 64.74%\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:    0.00091 Validation Accuracy: 66.26%\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:    0.00020 Validation Accuracy: 66.02%\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:    0.00024 Validation Accuracy: 64.98%\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:    0.00019 Validation Accuracy: 65.56%\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.00050 Validation Accuracy: 65.36%\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:    0.00312 Validation Accuracy: 65.94%\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:    0.00040 Validation Accuracy: 65.82%\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:    0.00034 Validation Accuracy: 64.34%\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:    0.00009 Validation Accuracy: 66.86%\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.02629 Validation Accuracy: 65.40%\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:    0.00024 Validation Accuracy: 66.04%\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:    0.00134 Validation Accuracy: 66.04%\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:    0.00065 Validation Accuracy: 64.34%\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:    0.00034 Validation Accuracy: 66.50%\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.00148 Validation Accuracy: 66.24%\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:    0.00019 Validation Accuracy: 64.70%\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:    0.00152 Validation Accuracy: 64.66%\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:    0.00058 Validation Accuracy: 64.74%\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:    0.00027 Validation Accuracy: 65.94%\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.00037 Validation Accuracy: 66.14%\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:    0.00052 Validation Accuracy: 66.70%\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:    0.00038 Validation Accuracy: 65.98%\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:    0.00017 Validation Accuracy: 65.40%\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:    0.00020 Validation Accuracy: 66.40%\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.00024 Validation Accuracy: 65.88%\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:    0.00015 Validation Accuracy: 66.94%\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:    0.00018 Validation Accuracy: 66.66%\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:    0.00044 Validation Accuracy: 65.74%\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:    0.00113 Validation Accuracy: 65.76%\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.00087 Validation Accuracy: 65.90%\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:    0.00012 Validation Accuracy: 66.16%\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:    0.00006 Validation Accuracy: 65.76%\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:    0.00018 Validation Accuracy: 64.82%\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:    0.00071 Validation Accuracy: 66.58%\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.00018 Validation Accuracy: 67.10%\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:    0.00053 Validation Accuracy: 65.82%\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:    0.00010 Validation Accuracy: 65.84%\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:    0.00017 Validation Accuracy: 64.98%\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:    0.00223 Validation Accuracy: 65.54%\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.00013 Validation Accuracy: 66.14%\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:    0.00021 Validation Accuracy: 66.94%\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:    0.00012 Validation Accuracy: 66.14%\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:    0.00020 Validation Accuracy: 65.70%\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:    0.00023 Validation Accuracy: 65.86%\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.00043 Validation Accuracy: 65.24%\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:    0.00040 Validation Accuracy: 65.98%\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:    0.00017 Validation Accuracy: 65.48%\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:    0.00073 Validation Accuracy: 65.70%\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:    0.00101 Validation Accuracy: 65.30%\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.00055 Validation Accuracy: 66.40%\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:    0.00013 Validation Accuracy: 65.70%\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.30%\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:    0.00068 Validation Accuracy: 65.14%\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:    0.00031 Validation Accuracy: 66.16%\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.00022 Validation Accuracy: 66.24%\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:    0.00015 Validation Accuracy: 65.40%\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:    0.00023 Validation Accuracy: 64.08%\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:    0.00133 Validation Accuracy: 65.76%\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:    0.00026 Validation Accuracy: 65.86%\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.00008 Validation Accuracy: 65.94%\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:    0.00005 Validation Accuracy: 65.74%\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:    0.00074 Validation Accuracy: 65.22%\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:    0.00172 Validation Accuracy: 66.68%\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:    0.00125 Validation Accuracy: 66.04%\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 66.46%\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:    0.00011 Validation Accuracy: 64.94%\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:    0.00020 Validation Accuracy: 65.98%\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:    0.00056 Validation Accuracy: 65.68%\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:    0.00027 Validation Accuracy: 66.12%\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.00016 Validation Accuracy: 65.72%\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:    0.00004 Validation Accuracy: 66.50%\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:    0.00036 Validation Accuracy: 66.18%\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:    0.00014 Validation Accuracy: 65.98%\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:    0.00065 Validation Accuracy: 66.82%\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.00035 Validation Accuracy: 65.82%\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:    0.00010 Validation Accuracy: 65.26%\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:    0.00003 Validation Accuracy: 66.08%\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:    0.00023 Validation Accuracy: 65.10%\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:    0.00019 Validation Accuracy: 65.38%\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.00015 Validation Accuracy: 65.94%\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:    0.00035 Validation Accuracy: 65.02%\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 65.32%\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:    0.00004 Validation Accuracy: 66.06%\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:    0.00025 Validation Accuracy: 65.84%\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.00039 Validation Accuracy: 65.66%\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 66.30%\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:    0.00013 Validation Accuracy: 65.74%\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:    0.00009 Validation Accuracy: 65.18%\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:    0.00057 Validation Accuracy: 65.00%\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.00043 Validation Accuracy: 65.60%\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 66.10%\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:    0.00046 Validation Accuracy: 66.44%\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:    0.00003 Validation Accuracy: 66.48%\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:    0.00003 Validation Accuracy: 66.36%\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.00008 Validation Accuracy: 67.08%\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:    0.00005 Validation Accuracy: 66.48%\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:    0.00018 Validation Accuracy: 66.72%\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:    0.00004 Validation Accuracy: 65.94%\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:    0.00008 Validation Accuracy: 66.50%\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.00128 Validation Accuracy: 66.00%\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:    0.00103 Validation Accuracy: 65.40%\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.58%\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:    0.00040 Validation Accuracy: 66.48%\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:    0.00016 Validation Accuracy: 65.94%\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.00039 Validation Accuracy: 65.74%\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.02%\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:    0.00002 Validation Accuracy: 66.62%\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:    0.00192 Validation Accuracy: 66.24%\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:    0.00010 Validation Accuracy: 64.88%\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.00010 Validation Accuracy: 65.12%\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:    0.00006 Validation Accuracy: 65.98%\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:    0.00003 Validation Accuracy: 65.00%\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:    0.00047 Validation Accuracy: 64.70%\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:    0.00007 Validation Accuracy: 65.66%\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.00007 Validation Accuracy: 65.80%\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:    0.00026 Validation Accuracy: 65.96%\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:    0.00003 Validation Accuracy: 65.40%\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:    0.00023 Validation Accuracy: 65.52%\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:    0.00021 Validation Accuracy: 64.62%\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.00050 Validation Accuracy: 66.28%\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:    0.00015 Validation Accuracy: 65.48%\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.12%\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:    0.00014 Validation Accuracy: 66.16%\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:    0.00004 Validation Accuracy: 66.14%\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.00012 Validation Accuracy: 66.48%\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:    0.00011 Validation Accuracy: 65.46%\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:    0.00002 Validation Accuracy: 65.84%\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:    0.00004 Validation Accuracy: 66.80%\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:    0.00013 Validation Accuracy: 66.28%\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.00012 Validation Accuracy: 65.76%\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:    0.00004 Validation Accuracy: 65.06%\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.00%\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:    0.00579 Validation Accuracy: 66.14%\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:    0.00004 Validation Accuracy: 65.40%\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 65.90%\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 65.78%\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:    0.00011 Validation Accuracy: 66.22%\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:    0.00441 Validation Accuracy: 65.16%\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:    0.00026 Validation Accuracy: 66.54%\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.00007 Validation Accuracy: 66.44%\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:    0.00031 Validation Accuracy: 66.28%\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:    0.00012 Validation Accuracy: 66.06%\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:    0.00011 Validation Accuracy: 65.10%\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:    0.00004 Validation Accuracy: 64.82%\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.00008 Validation Accuracy: 64.50%\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:    0.00097 Validation Accuracy: 65.48%\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.10%\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:    0.00006 Validation Accuracy: 65.84%\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:    0.00002 Validation Accuracy: 65.94%\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.00022 Validation Accuracy: 65.72%\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:    0.00007 Validation Accuracy: 65.86%\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:    0.00002 Validation Accuracy: 65.88%\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:    0.00012 Validation Accuracy: 66.22%\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:    0.00003 Validation Accuracy: 65.94%\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.00013 Validation Accuracy: 65.88%\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:    0.00003 Validation Accuracy: 65.88%\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.48%\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:    0.00006 Validation Accuracy: 65.34%\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:    0.00005 Validation Accuracy: 65.50%\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 66.46%\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:    0.00166 Validation Accuracy: 64.88%\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:    0.00023 Validation Accuracy: 65.54%\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:    0.00001 Validation Accuracy: 66.18%\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:    0.00029 Validation Accuracy: 65.60%\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 65.86%\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:    0.00038 Validation Accuracy: 65.80%\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:    0.00003 Validation Accuracy: 66.20%\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:    0.00011 Validation Accuracy: 65.70%\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:    0.00149 Validation Accuracy: 66.68%\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.00007 Validation Accuracy: 66.44%\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:    0.00022 Validation Accuracy: 65.78%\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 65.10%\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:    0.00003 Validation Accuracy: 66.20%\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:    0.00004 Validation Accuracy: 64.72%\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.00059 Validation Accuracy: 66.06%\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:    0.00750 Validation Accuracy: 66.44%\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:    0.00012 Validation Accuracy: 65.88%\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:    0.00011 Validation Accuracy: 63.96%\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:    0.00046 Validation Accuracy: 66.18%\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 65.56%\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:    0.00016 Validation Accuracy: 66.74%\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:    0.00009 Validation Accuracy: 66.28%\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:    0.00002 Validation Accuracy: 66.98%\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:    0.00008 Validation Accuracy: 66.90%\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 65.90%\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:    0.00020 Validation Accuracy: 66.16%\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:    0.00057 Validation Accuracy: 65.96%\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:    0.00014 Validation Accuracy: 66.08%\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:    0.00003 Validation Accuracy: 66.92%\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 66.92%\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:    0.00008 Validation Accuracy: 66.38%\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:    0.00003 Validation Accuracy: 66.96%\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:    0.00041 Validation Accuracy: 65.58%\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:    0.00001 Validation Accuracy: 66.26%\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 67.02%\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:    0.00003 Validation Accuracy: 66.04%\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.98%\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:    0.00042 Validation Accuracy: 66.58%\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:    0.00138 Validation Accuracy: 66.12%\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.00014 Validation Accuracy: 66.02%\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:    0.00021 Validation Accuracy: 66.16%\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.04%\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:    0.00008 Validation Accuracy: 64.90%\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:    0.00003 Validation Accuracy: 66.34%\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 65.42%\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:    0.00004 Validation Accuracy: 66.30%\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.98%\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:    0.00002 Validation Accuracy: 66.66%\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:    0.00024 Validation Accuracy: 66.30%\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.00004 Validation Accuracy: 66.72%\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 66.14%\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.50%\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:    0.00001 Validation Accuracy: 66.74%\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:    0.00024 Validation Accuracy: 66.78%\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 66.58%\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 65.72%\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.02%\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:    0.00006 Validation Accuracy: 66.84%\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:    0.00002 Validation Accuracy: 67.14%\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.00002 Validation Accuracy: 66.18%\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 65.68%\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.32%\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:    0.00020 Validation Accuracy: 64.90%\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:    0.00003 Validation Accuracy: 66.38%\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.00010 Validation Accuracy: 65.18%\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 66.02%\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:    0.00005 Validation Accuracy: 66.36%\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:    0.00001 Validation Accuracy: 66.26%\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.62%\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 67.00%\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.30%\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.70%\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:    0.00008 Validation Accuracy: 66.20%\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:    0.00002 Validation Accuracy: 66.60%\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 66.64%\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 65.80%\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.30%\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:    0.00002 Validation Accuracy: 66.32%\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:    0.00019 Validation Accuracy: 66.66%\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.00004 Validation Accuracy: 66.62%\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 66.08%\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:    0.00002 Validation Accuracy: 66.58%\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:    0.00320 Validation Accuracy: 64.58%\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:    0.00012 Validation Accuracy: 66.30%\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.00005 Validation Accuracy: 64.76%\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 66.86%\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.28%\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:    0.00003 Validation Accuracy: 65.66%\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:    0.00014 Validation Accuracy: 65.84%\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 66.22%\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:    0.00004 Validation Accuracy: 65.96%\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.90%\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 66.32%\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:    0.00004 Validation Accuracy: 66.72%\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 66.16%\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:    0.00007 Validation Accuracy: 65.96%\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.10%\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:    0.00040 Validation Accuracy: 65.92%\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:    0.00001 Validation Accuracy: 66.32%\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 65.38%\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.06%\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.36%\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:    0.00023 Validation Accuracy: 65.58%\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:    0.00134 Validation Accuracy: 66.36%\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.00019 Validation Accuracy: 65.34%\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:    0.00007 Validation Accuracy: 66.00%\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:    0.00002 Validation Accuracy: 65.14%\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:    0.00019 Validation Accuracy: 66.14%\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:    0.00014 Validation Accuracy: 66.28%\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 66.00%\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:    0.00005 Validation Accuracy: 65.60%\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.46%\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:    0.00008 Validation Accuracy: 66.76%\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:    0.00001 Validation Accuracy: 66.82%\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.00026 Validation Accuracy: 66.56%\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 64.96%\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:    0.00006 Validation Accuracy: 66.30%\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:    0.00020 Validation Accuracy: 66.06%\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 67.00%\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.00054 Validation Accuracy: 65.20%\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 67.14%\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.60%\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:    0.00012 Validation Accuracy: 65.58%\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:    0.00010 Validation Accuracy: 66.92%\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 66.58%\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 65.92%\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:    0.00040 Validation Accuracy: 64.94%\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:    0.00023 Validation Accuracy: 65.86%\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:    0.00012 Validation Accuracy: 66.30%\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 65.06%\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.40%\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.18%\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:    0.00001 Validation Accuracy: 67.10%\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.16%\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.00008 Validation Accuracy: 65.74%\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 66.52%\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 65.56%\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:    0.00003 Validation Accuracy: 65.10%\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.22%\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.00009 Validation Accuracy: 65.50%\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:    0.00009 Validation Accuracy: 64.88%\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.02%\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:    0.00005 Validation Accuracy: 66.44%\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:    0.00023 Validation Accuracy: 66.80%\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 66.34%\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:    0.00003 Validation Accuracy: 65.76%\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.36%\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:    0.00005 Validation Accuracy: 65.66%\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:    0.00003 Validation Accuracy: 66.62%\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.00008 Validation Accuracy: 66.40%\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:    0.00003 Validation Accuracy: 65.60%\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.52%\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:    0.00003 Validation Accuracy: 66.52%\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:    0.00237 Validation Accuracy: 65.28%\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 66.58%\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:    0.00002 Validation Accuracy: 65.66%\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.36%\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 66.84%\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.80%\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 64.52%\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.36%\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 66.06%\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:    0.00002 Validation Accuracy: 65.70%\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:    0.00004 Validation Accuracy: 65.24%\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 66.06%\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:    0.00017 Validation Accuracy: 64.10%\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 65.34%\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 66.22%\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.32%\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.00006 Validation Accuracy: 65.50%\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:    0.00006 Validation Accuracy: 66.74%\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.78%\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:    0.00002 Validation Accuracy: 65.30%\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:    0.00002 Validation Accuracy: 66.72%\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 66.96%\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 66.12%\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.44%\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 65.56%\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.88%\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 67.12%\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:    0.00071 Validation Accuracy: 65.48%\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:    0.00001 Validation Accuracy: 65.40%\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 65.58%\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.48%\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 65.62%\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:    0.00001 Validation Accuracy: 65.80%\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.88%\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 66.12%\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:    0.00001 Validation Accuracy: 67.38%\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 66.30%\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.44%\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.78%\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:    0.00001 Validation Accuracy: 66.18%\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.24%\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.00001 Validation Accuracy: 66.00%\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.92%\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.02%\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 66.54%\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:    0.00030 Validation Accuracy: 65.62%\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.00012 Validation Accuracy: 64.92%\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 65.56%\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 64.88%\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:    0.00000 Validation Accuracy: 66.28%\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:    0.00010 Validation Accuracy: 66.18%\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.00003 Validation Accuracy: 65.46%\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.40%\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 64.62%\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:    0.00031 Validation Accuracy: 65.16%\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:    0.00000 Validation Accuracy: 66.18%\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.00059 Validation Accuracy: 65.04%\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 66.42%\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 66.52%\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:    0.00006 Validation Accuracy: 65.64%\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:    0.00005 Validation Accuracy: 65.64%\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.00000 Validation Accuracy: 66.08%\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:    0.00000 Validation Accuracy: 65.98%\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:    0.00000 Validation Accuracy: 65.16%\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:    0.00005 Validation Accuracy: 66.18%\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:    0.00005 Validation Accuracy: 65.16%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6383504746835443\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwPlCZJ8BiKFqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff01c2459b0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
